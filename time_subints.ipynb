{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Programa para separar las observaciones en sub-integraciones temporales\n",
    "\n",
    "Las observaciones deben estar dentro de un directorio llamado './pfds/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos los paquetes que vamos a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pypulse as pulsar\n",
    "import matplotlib.pyplot as plt     # para graficar\n",
    "\n",
    "import numpy as np\n",
    "import glob                         # para hacer listas de archivo\n",
    "import subprocess                   # para usar subprocesos\n",
    "\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ant = \"A2\"     # antena usada (A1 o A2)\n",
    "year = \"2020\"  # año de las observaciones\n",
    "t_min = 2000   # duración mínima de las subintegraciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una lista con todos los archivos .pfd de observaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('./pfds/')                         # entramos al directorio que contiene los .pfds\n",
    "pfd_files = glob.glob('*' + ant + '_' + year + '*pfd')                           # lista de archivos .pfd\n",
    "\n",
    "#print(pfd_files)\n",
    "print(\"Numero de observaciones = \" + str(len(pfd_files)))\n",
    "\n",
    "output = \"./results_\" + ant + '_' + year + '_subints_' + str(t_min) + '.txt'     # archivo que contendrá S/N y t_obs\n",
    "list = open(output, \"w+\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procesamos las observaciones usando PyPulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert PFD files to PSRFITS\n",
    "\n",
    "for pfd in pfd_files:\n",
    "    subprocess.check_call(['psrconv','-o','PSRFITS','-e','fits',pfd])\n",
    "    \n",
    "# Save all PSRFITS files\n",
    "psrfits_files = glob.glob('*' + ant + '_' + year + '*fits')\n",
    "\n",
    "# Load all PSRFITS into PyPulse\n",
    "fits_pypulse= []\n",
    "for psrfits in psrfits_files:\n",
    "    temp_pypulse= pulsar.Archive(psrfits)\n",
    "    fits_pypulse.append(temp_pypulse)\n",
    "\n",
    "observations = dict(zip(psrfits_files, fits_pypulse))\n",
    "\n",
    "# Create single pulse object\n",
    "# Creat array of best profiles\n",
    "\n",
    "single_pulses=[]\n",
    "\n",
    "for observation in fits_pypulse:\n",
    "    \n",
    "    if observation.getDuration() > t_min:\n",
    "    \n",
    "    # First crunch in time and frequency\n",
    "    \n",
    "        n_subint = int((observation.getDuration()) // t_min) # número de subintegraciones para esta observación\n",
    "\n",
    "        observation.fscrunch()\n",
    "        observation.tscrunch(nsubint=n_subint)               # separamos en subintegraciones\n",
    "    \n",
    "#       print(\"Número de subintegraciones = \" + str(observation.getNsubint()))\n",
    "#       print(\"Duración de la observación total = \" + str(observation.getDuration()/60))\n",
    "#       print(\"Duración de cada subintegración = \" + str(observation.getDurations()/60))\n",
    "    \n",
    "    # Now get array of the best profile\n",
    "    \n",
    "        tmp_singlepulse = observation.getSinglePulses( windowsize = int(observation.getNbin()/4 ))\n",
    "        \n",
    "        if n_subint == 1:   # en caso de que no haya subintegraciones, debe tratarse a la observación como única\n",
    "        \n",
    "            # Align and normalize\n",
    "            tmp_singlepulse.center_align()\n",
    "            tmp_singlepulse.normalize()\n",
    "        \n",
    "            file = str(observation).replace(\".fits\", \".pfd\")\n",
    "            t_obs = observation.getDuration()/60                          # calculamos el tiempo de integración en minutos\n",
    "            sn_obs = tmp_singlepulse.getSN()                              # calculamos el S/N de la observación\n",
    " \n",
    "            list.write(file + \"   \" + str(sn_obs) + \"   \" + str(t_obs) + \"\\n\")  # y escribimos el S/N y el t_obs en el archivo de salida\n",
    "    \n",
    "        # Save aligned and normalize in each observation\n",
    "            single_pulses.append(tmp_singlepulse)\n",
    "            \n",
    "        \n",
    "        elif n_subint > 1:  # en caso de que sí haya subintegraciones, debe analizarse cada una por separado\n",
    "    \n",
    "            for n in range(observation.getNsubint()):  # barremos todas las subintegraciones\n",
    "            \n",
    "            # Align and normalize\n",
    "                tmp_singlepulse[n].center_align()\n",
    "                tmp_singlepulse[n].normalize()\n",
    "    \n",
    "#        print(\"S/N de la \" + str(n) + \"-esima subintegración = \" + str(tmp_singlepulse[n].getSN()))\n",
    "        \n",
    "                file = str(observation).replace(\".fits\", \".pfd\")\n",
    "                t_obs = observation.getDurations()[n] / 60               # calculamos el tiempo de integración en minutos\n",
    "                sn_obs = tmp_singlepulse[n].getSN()                      # calculamos el S/N de la observación\n",
    " \n",
    "                list.write(file + \"   \" + str(sn_obs) + \"   \" + str(t_obs) + \"\\n\")  # y escribimos el S/N y el t_obs en el archivo de salida\n",
    "            \n",
    "                # Save aligned and normalize in each observation\n",
    "                single_pulses.append(tmp_singlepulse[n])\n",
    "    \n",
    "sp_observations = dict(zip(psrfits_files, single_pulses))\n",
    "\n",
    "list.close()                               # cerramos el archivo de salida\n",
    "\n",
    "os.chdir('..')                             # salimos de directorio que contiene los .pfds\n",
    "\n",
    "shutil.move(\"./pfds/\" + output, './')      # movemos el archivo con los resultados al directorio raíz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que tenemos los datos para las observaciones de todos los años, podemos juntarlos en un único archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = glob.glob(\"results_\" + ant + '*' + '_subints_' + str(t_min) + '.txt')\n",
    "with open(\"./results_\" + ant + \"_subints_\" + str(t_min) + \".txt\", 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
